{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>coil</th>\n",
       "      <th>furnace Number</th>\n",
       "      <th>analyse</th>\n",
       "      <th>Hardness_1</th>\n",
       "      <th>Hardness_2</th>\n",
       "      <th>Width</th>\n",
       "      <th>Temperature before finishing mill</th>\n",
       "      <th>Temperature after finishing mill</th>\n",
       "      <th>Thickness</th>\n",
       "      <th>...</th>\n",
       "      <th>al</th>\n",
       "      <th>ma</th>\n",
       "      <th>b</th>\n",
       "      <th>n</th>\n",
       "      <th>ti</th>\n",
       "      <th>cr</th>\n",
       "      <th>va</th>\n",
       "      <th>mo</th>\n",
       "      <th>difference</th>\n",
       "      <th>constriction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>396378</td>\n",
       "      <td>1</td>\n",
       "      <td>K371</td>\n",
       "      <td>10003</td>\n",
       "      <td>101</td>\n",
       "      <td>1302.1</td>\n",
       "      <td>1147</td>\n",
       "      <td>921</td>\n",
       "      <td>4.36</td>\n",
       "      <td>...</td>\n",
       "      <td>304</td>\n",
       "      <td>291</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.783333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>396376</td>\n",
       "      <td>3</td>\n",
       "      <td>K371</td>\n",
       "      <td>10123</td>\n",
       "      <td>101</td>\n",
       "      <td>1282.3</td>\n",
       "      <td>1150</td>\n",
       "      <td>920</td>\n",
       "      <td>4.37</td>\n",
       "      <td>...</td>\n",
       "      <td>395</td>\n",
       "      <td>384</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>189</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>396377</td>\n",
       "      <td>4</td>\n",
       "      <td>K321</td>\n",
       "      <td>10040</td>\n",
       "      <td>102</td>\n",
       "      <td>1297.4</td>\n",
       "      <td>1183</td>\n",
       "      <td>933</td>\n",
       "      <td>4.43</td>\n",
       "      <td>...</td>\n",
       "      <td>476</td>\n",
       "      <td>463</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>-1.866667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>396379</td>\n",
       "      <td>3</td>\n",
       "      <td>K371</td>\n",
       "      <td>10243</td>\n",
       "      <td>102</td>\n",
       "      <td>1295.2</td>\n",
       "      <td>1165</td>\n",
       "      <td>910</td>\n",
       "      <td>4.44</td>\n",
       "      <td>...</td>\n",
       "      <td>306</td>\n",
       "      <td>296</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>396380</td>\n",
       "      <td>4</td>\n",
       "      <td>K321</td>\n",
       "      <td>10012</td>\n",
       "      <td>100</td>\n",
       "      <td>1293.3</td>\n",
       "      <td>1192</td>\n",
       "      <td>909</td>\n",
       "      <td>3.95</td>\n",
       "      <td>...</td>\n",
       "      <td>340</td>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    coil  furnace Number analyse  Hardness_1  Hardness_2   Width  \\\n",
       "0           0  396378               1   K371        10003         101  1302.1   \n",
       "1           1  396376               3   K371        10123         101  1282.3   \n",
       "2           2  396377               4   K321        10040         102  1297.4   \n",
       "3           3  396379               3   K371        10243         102  1295.2   \n",
       "4           4  396380               4   K321        10012         100  1293.3   \n",
       "\n",
       "   Temperature before finishing mill  Temperature after finishing mill  \\\n",
       "0                               1147                               921   \n",
       "1                               1150                               920   \n",
       "2                               1183                               933   \n",
       "3                               1165                               910   \n",
       "4                               1192                               909   \n",
       "\n",
       "   Thickness  ...   al   ma  b   n  ti   cr  va  mo  difference  constriction  \n",
       "0       4.36  ...  304  291  1  34   6  302   0  25   -0.783333             0  \n",
       "1       4.37  ...  395  384  1  33  12  189  25   7   -0.300000             0  \n",
       "2       4.43  ...  476  463  1  20  11  288   0  40   -1.866667             0  \n",
       "3       4.44  ...  306  296  1  21   9  253   0   9   -0.166667             0  \n",
       "4       3.95  ...  340  329  1  28   8  297   0  23   -0.800000             0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting difference to be 4\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\masud\\Documents\\Steel-Project\\Final_csv.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column\n",
    "df = df.drop(['Unnamed: 0','Thickness profile','difference'], axis = 1)\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['coil', 'furnace Number', 'analyse', 'Hardness_1', 'Hardness_2',\n",
       "       'Width', 'Temperature before finishing mill',\n",
       "       'Temperature after finishing mill', 'Thickness', 'c', 'mn', 'si', 'nb',\n",
       "       'p', 's', 'al', 'ma', 'b', 'n', 'ti', 'cr', 'va', 'mo', 'constriction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting independent variable\n",
    "X= df[['Width','Temperature before finishing mill','al','b', 'ma','nb']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting dependent variable\n",
    "y= df.iloc[:,-1].values \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For splitting the dataset, \n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# fitting  and transforming the training dataset.\n",
    "\n",
    "st_x= StandardScaler()  \n",
    "X_train= st_x.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting  and transforming the test dataset\n",
    "X_test= st_x.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler #fixed import\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Binary Classification Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.8722431414739107\n",
      "score on train: 0.8703126751092681\n"
     ]
    }
   ],
   "source": [
    "#1  Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB().fit(X_train, y_train)\n",
    "print(\"score on test: \" + str(mnb.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(mnb.score(X_train, y_train)))\n",
    "\n",
    "#score on test: 0.8722431414739107\n",
    "#score on train: 0.8703126751092681\n",
    "\n",
    "# duration: 0.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.8628294782140936\n",
      "score on train: 0.8636557211700101\n"
     ]
    }
   ],
   "source": [
    "#2  Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr=LogisticRegression(max_iter=100)\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"score on test: \" + str(lr.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(lr.score(X_train, y_train)))\n",
    "\n",
    "#score on test: 0.8628294782140936\n",
    "#score on train: 0.8636557211700101\n",
    "\n",
    "# duration: 0.2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (44615, 6)\n",
      "score on test: 0.8951945490407028\n",
      "score on train: 0.9133699428443348\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbours\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(algorithm = 'brute', n_jobs=-1)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"train shape: \" + str(X_train.shape))\n",
    "print(\"score on test: \" + str(knn.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(knn.score(X_train, y_train)))\n",
    "\n",
    "#train shape: (44615, 6)\n",
    "#score on test: 0.8951945490407028\n",
    "#score on train: 0.9133699428443348\n",
    "\n",
    "#durations: 2m 13.8s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.8722431414739107\n",
      "score on train: 0.8703126751092681\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm=LinearSVC(C=0.0001)\n",
    "svm.fit(X_train, y_train)\n",
    "print(\"score on test: \" + str(svm.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(svm.score(X_train, y_train)))\n",
    "\n",
    "#score on test: 0.8722431414739107\n",
    "#score on train: 0.8703126751092681"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.849919311457773\n",
      "score on train: 0.9999551720273451\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"score on test: \"  + str(clf.score(X_test, y_test)))\n",
    "print(\"score on train: \" + str(clf.score(X_train, y_train)))\n",
    "\n",
    "#score on test: 0.849919311457773\n",
    "#score on train: 0.9999551720273451\n",
    "\n",
    "#durations: 0.3s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.8983324367939752\n",
      "score on train: 0.9495685307631963\n"
     ]
    }
   ],
   "source": [
    "# Bagging Decision Tree (Ensemble Learning I)\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# max_samples: maximum size 0.5=50% of each sample taken from the full dataset\n",
    "# max_features: maximum of features 1=100% taken here all 10K \n",
    "# n_estimators: number of decision trees \n",
    "\n",
    "bg=BaggingClassifier(DecisionTreeClassifier(),max_samples=0.5,max_features=1.0,n_estimators=10)\n",
    "bg.fit(X_train, y_train)\n",
    "print(\"score on test: \" + str(bg.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(bg.score(X_train, y_train)))\n",
    "\n",
    "#score on test: 0.8983324367939752\n",
    "#score on train: 0.9495685307631963\n",
    "\n",
    "# duration 1.2s\n",
    "\n",
    "#The Bagging Classifier is much slower as it basically runs 10 decision trees \n",
    "# but one can see a reduction of the overfitting we saw on the single Decision \n",
    "# Tree and an increase in the test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.8923256230948539\n",
      "score on train: 0.8928387313683739\n"
     ]
    }
   ],
   "source": [
    "#  Boosting Decision Tree (Ensemble Learning II)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(min_samples_split=10,max_depth=4),n_estimators=10,learning_rate=0.6)\n",
    "adb.fit(X_train, y_train)\n",
    "\n",
    "print(\"score on test: \" + str(adb.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(adb.score(X_train, y_train)))\n",
    "\n",
    "\n",
    "#score on test: 0.8923256230948539\n",
    "#score on train: 0.8928387313683739"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score on test: 0.8980634749865519\n",
      "score on train: 0.9024543315028578\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (Ensemble Learning III)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# n_estimators = number of decision trees\n",
    "rf = RandomForestClassifier(n_estimators=30, max_depth=9)\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"score on test: \" + str(rf.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(rf.score(X_train, y_train)))\n",
    "\n",
    "#score on test: 0.8980634749865519\n",
    "#score on train: 0.9024543315028578\n",
    "\n",
    "#duration 1.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "86/86 [==============================] - 1s 4ms/step - loss: 0.5539 - accuracy: 0.8441 - val_loss: 0.4466 - val_accuracy: 0.8650\n",
      "Epoch 2/4\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8704 - val_loss: 0.3846 - val_accuracy: 0.8650\n",
      "Epoch 3/4\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8704 - val_loss: 0.3698 - val_accuracy: 0.8650\n",
      "Epoch 4/4\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8704 - val_loss: 0.3590 - val_accuracy: 0.8650\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8722\n",
      "score on test: 0.8722431659698486\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.3495 - accuracy: 0.8703\n",
      "score on train: 0.8703126907348633\n"
     ]
    }
   ],
   "source": [
    "#Neural Network (Deep Learning)\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "# split an additional validation dataset\n",
    "x_validation=X_train[:1000]\n",
    "x_partial_train=X_train[1000:]\n",
    "y_validation=y_train[:1000]\n",
    "y_partial_train=y_train[1000:]\n",
    "\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(16,activation='relu',input_shape=(6,)))\n",
    "model.add(layers.Dense(16,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_partial_train,y_partial_train,epochs=4,batch_size=512,validation_data=(x_validation,y_validation))\n",
    "print(\"score on test: \" + str(model.evaluate(X_test,y_test)[1]))\n",
    "print(\"score on train: \"+ str(model.evaluate(X_train,y_train)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "86/86 [==============================] - 1s 4ms/step - loss: 0.6179 - accuracy: 0.7754 - val_loss: 0.5221 - val_accuracy: 0.8650\n",
      "Epoch 2/4\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.8597 - val_loss: 0.4586 - val_accuracy: 0.8650\n",
      "Epoch 3/4\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8704 - val_loss: 0.4176 - val_accuracy: 0.8650\n",
      "Epoch 4/4\n",
      "86/86 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.8704 - val_loss: 0.4051 - val_accuracy: 0.8650\n",
      "349/349 [==============================] - 0s 1ms/step - loss: 0.3927 - accuracy: 0.8722\n",
      "score on test: 0.8722431659698486\n",
      "1395/1395 [==============================] - 2s 1ms/step - loss: 0.3958 - accuracy: 0.8703\n",
      "score on train: 0.8703126907348633\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "# add validation dataset\n",
    "validation_split=1000\n",
    "x_validation=X_train[:validation_split]\n",
    "x_partial_train=X_train[validation_split:]\n",
    "y_validation=y_train[:validation_split]\n",
    "y_partial_train=y_train[validation_split:]\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(8,kernel_regularizer=regularizers.l2(0.003),activation='relu',input_shape=(6,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(8,kernel_regularizer=regularizers.l2(0.003),activation='relu'))\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_partial_train,y_partial_train,epochs=4,batch_size=512,validation_data=(x_validation,y_validation))\n",
    "print(\"score on test: \" + str(model.evaluate(X_test,y_test)[1]))\n",
    "print(\"score on train: \"+ str(model.evaluate(X_train,y_train)[1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0ec2fa64e559bcf1e26b72294f8d7964640e4d45d429ea8cc58c0ee1727d470"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
